# -*- coding: utf-8 -*-
"""SentimentAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13TYkdqYDYGm3duFzgelsK11JrqEJ7hfj
"""

# Step 1: Install Required Libraries
!pip install requests pandas nltk

# Step 2: Import Libraries
import requests
import pandas as pd
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Step 3: Setup Airtable API Credentials
AIRTABLE_API_KEY = "patWoTkjqabw7jy0J.d1d4860ef9fbc5041c2c06f938bf341c8e6f207ead18f13bcbd493cd49543f0b"  # Replace with your actual API key
BASE_ID = "FinalProject"  # Replace with your Airtable Base ID
TABLE_NAME = "Zoom Review Data"

# Step 4: Fetch Data from Airtable
def fetch_airtable_data():
    url = f"https://api.airtable.com/v0/FinalProject/Zoom Review Data"
    headers = {
        "Authorization": f"Bearer {AIRTABLE_API_KEY}"
    }

    all_records = []
    offset = None

    while True:
        response = requests.get(url, headers=headers, params={"offset": offset} if offset else {})
        data = response.json()
        all_records.extend(data.get("records", []))
        offset = data.get("offset")

        if not offset:
            break

    # Check if any records were fetched and if they contain 'fields'
    if all_records and "fields" in all_records[0]:
        return pd.DataFrame([record["fields"] for record in all_records])
    else:
        # Return an empty DataFrame with the expected columns if no data or 'fields' are found
        return pd.DataFrame(columns=['Review', 'Rating'])
    #return pd.DataFrame([record["fields"] for record in all_records])

# Step 5: Perform Sentiment Analysis
nltk.download('vader_lexicon')
sia = SentimentIntensityAnalyzer()

def analyze_sentiment(row):
    # Text sentiment score
    text_sentiment = sia.polarity_scores(row["Review"])["compound"]

    # Normalize rating to a scale of -1 to 1 (1-star = -1, 3-star = 0, 5-star = +1)
    rating_normalized = (row["Rating"] - 3) / 2  # Range: -1 (bad) to +1 (good)

    # Weighted Sentiment Score
    overall_sentiment = (text_sentiment * 0.7) + (rating_normalized * 0.3)

    return overall_sentiment

# Step 6: Compute Overall Sentiment Score
def compute_sentiment():
    records = fetch_airtable_data()

    if not records:
        print("No data found in Airtable.")
        return None, 0

    # Extract necessary fields
    data = []
    for record in records:
        fields = record.get("fields", {})
        review = fields.get("Review", "")
        rating = fields.get("Rating", 3)  # Default neutral if rating missing
        data.append({"Review": review, "Rating": rating})

    # Convert to DataFrame
    df = pd.DataFrame(data)

    # Initialize Sentiment Analyzer
    sia = SentimentIntensityAnalyzer()

    # Compute Sentiment Score
    df["Sentiment Score"] = df["Review"].apply(lambda x: sia.polarity_scores(x)["compound"])

    # Normalize the Rating to a Sentiment Score (-1 to 1)
    df["Normalized Rating"] = (df["Rating"] - 3) / 2  # Scale: 1-5 -> -1 to 1

    # Average Sentiment = (Text Sentiment + Normalized Rating) / 2
    df["Final Sentiment"] = (df["Sentiment Score"] + df["Normalized Rating"]) / 2

    # Compute Percentage of Positive Sentiment
    positive_reviews = df[df["Final Sentiment"] > 0].shape[0]
    total_reviews = df.shape[0]

    positive_percentage = (positive_reviews / total_reviews) * 100 if total_reviews > 0 else 0

    return df, positive_percentage

# Run Analysis
df, positive_percentage = compute_sentiment()

# Display Output
print(f"Overall Positive Sentiment: {positive_percentage:.2f}%")
print(df.head())  # Show sample output

import pandas as pd
import requests
import json
from nltk.sentiment import SentimentIntensityAnalyzer
import nltk
!pip install langdetect
from langdetect import detect, DetectorFactory
from langdetect.lang_detect_exception import LangDetectException

# Ensure consistent language detection
DetectorFactory.seed = 0

# Download VADER lexicon if not already available
nltk.download('vader_lexicon')

# Airtable API Config
AIRTABLE_API_KEY = "patWoTkjqabw7jy0J.a572ccaacd59b816f6f3f9397314ab3617713b3709a2d6856f1cc2dd47c49aed"  # Replace with your actual API key
BASE_ID = "appbKcenyqWzvCkqC"  # Replace with your Airtable Base ID
TABLE_NAME = "zoomreviewdata"

# Fetch data from Airtable
def fetch_airtable_data():
    url = f"https://api.airtable.com/v0/appbKcenyqWzvCkqC/zoomreviewdata"
    headers = {
        "Authorization": f"Bearer {AIRTABLE_API_KEY}",
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        records = response.json().get("records", [])
        return records
    else:
        print("Error fetching data:", response.text)
        return []

# Function to check if a text is English
def is_english(text):
    try:
        return detect(text) == "en"
    except LangDetectException:
        return False  # If detection fails, assume it's not English

# Sentiment Analysis Function
def compute_sentiment():
    records = fetch_airtable_data()

    if records is None or len(records) == 0:
        print("No data found in Airtable.")
        return pd.DataFrame(), 0  # Return empty DataFrame and 0%

    # Extract necessary fields
    data = []
    for record in records:
        fields = record.get("fields", {})
        review = fields.get("Review", "")
        rating = fields.get("Rating", 3)  # Default neutral if missing

        # Only include English reviews
        if isinstance(review, str) and is_english(review):
            data.append({"Review": review, "Rating": rating})

    # Convert to DataFrame
    df = pd.DataFrame(data)

    if df.empty:
        print("No valid English reviews found.")
        return df, 0  # Return empty DataFrame and 0%

    # Initialize Sentiment Analyzer
    sia = SentimentIntensityAnalyzer()

    # Compute Sentiment Score
    df["Sentiment Score"] = df["Review"].apply(lambda x: sia.polarity_scores(x)["compound"])

    # Normalize the Rating to a Sentiment Score (-1 to 1)
    df["Normalized Rating"] = (df["Rating"] - 3) / 2  # Scale: 1-5 -> -1 to 1

    # Average Sentiment = (Text Sentiment + Normalized Rating) / 2
    df["Final Sentiment"] = (df["Sentiment Score"] + df["Normalized Rating"]) / 2

    # Compute Percentage of Positive Sentiment
    positive_reviews = df[df["Final Sentiment"] > 0].shape[0]
    total_reviews = df.shape[0]

    positive_percentage = (positive_reviews / total_reviews) * 100 if total_reviews > 0 else 0

    return df, positive_percentage

# Run Analysis
df, positive_percentage = compute_sentiment()

# Display Output
print(f"Overall Positive Sentiment: {positive_percentage:.2f}%")
print(df.head())  # Show sample output

import requests

# Airtable API Configuration
AIRTABLE_BASE_ID = "appScbEXV402S3pCE"  # Replace with your FinalProj1 base ID
AIRTABLE_TABLE_NAME = "sentiment"  # Your Sentiment Table name
AIRTABLE_API_KEY = "patWoTkjqabw7jy0J.a572ccaacd59b816f6f3f9397314ab3617713b3709a2d6856f1cc2dd47c49aed"

# Airtable API Endpoint
AIRTABLE_API_URL = f"https://api.airtable.com/v0/appScbEXV402S3pCE/sentiment"

# Headers for API Authentication
headers = {
    "Authorization": f"Bearer {AIRTABLE_API_KEY}",
    "Content-Type": "application/json"
}

def get_record_id():
    """Fetches the first available record ID from the Sentiment table."""
    response = requests.get(AIRTABLE_API_URL, headers=headers)

    if response.status_code == 200:
        records = response.json().get("records", [])
        if records:
            return records[0]["id"]  # Return the first record's ID
        else:
            print("❌ No records found in the Sentiment table.")
            return None
    else:
        print(f"❌ Error fetching records: {response.text}")
        return None

def update_sentiment_value(sentiment_percentage):
    """Updates the SentimentValue column in Airtable with the computed sentiment percentage."""
    record_id = get_record_id()
    if not record_id:
        print("⚠️ No record to update.")
        return

    data = {
        "records": [
            {
                "id": record_id,  # Airtable Record ID (Dynamically fetched)
                "fields": {
                    "SentimentValue": sentiment_percentage  # Field Name in Airtable
                }
            }
        ]
    }

    # Send PATCH request to update data
    response = requests.patch(AIRTABLE_API_URL, json=data, headers=headers)

    if response.status_code == 200:
        print(f"✅ Successfully updated record {record_id} with {sentiment_percentage}% sentiment.")
    else:
        print(f"❌ Error updating record {record_id}: {response.text}")

# Example Usage:
sentiment_percentage = positive_percentage  # Example sentiment value in percentage
update_sentiment_value(sentiment_percentage)

# prompt: Write me a code to understand from the reviews which are the best 5 features that the customers enjoyed or liked the most.

import pandas as pd
from collections import Counter


def analyze_best_features(df):
    """
    Analyzes customer reviews to identify the top 5 features they enjoyed the most.

    Args:
        df: Pandas DataFrame containing customer reviews.  Must have a 'Review' column.

    Returns:
        A list of the top 5 features.
    """
    if 'Review' not in df.columns:
        print("Error: 'Review' column not found in the DataFrame.")
        return []

    # Combine all reviews into a single string
    all_reviews = ' '.join(df['Review'].astype(str).tolist()).lower()  # Convert to lowercase

    # Define a list of potential features (expand this list based on your domain)
    potential_features = ["features", "interface", "performance", "reliability",  "collaboration", "screen sharing", "security", "cloud recording", "customer support", "price", "ease of use", "user experience", "integration", "mobile app", "video quality", "audio quality", "virtual background"]

    # Count the occurrences of each potential feature
    feature_counts = Counter({feature: all_reviews.count(feature) for feature in potential_features})

    # Get the top 5 most frequent features
    top_5_features = [feature for feature, count in feature_counts.most_common(5)]

    return top_5_features

# Example usage (assuming you have your DataFrame 'df' from previous code):
if 'df' in locals() and isinstance(df, pd.DataFrame):
    top_features = analyze_best_features(df)
    print("Top 5 features customers enjoyed:")
    for feature in top_features:
      print(feature)
else:
    print("DataFrame 'df' not found or not properly initialized. Please run the previous code blocks first.")

# prompt: based on the reviews which areas are the best performing for the customer list top 5 and also list 5 areas which are not doing good and can improve in future.

import pandas as pd
def analyze_worst_features(df):
    """
    Analyzes customer reviews to identify areas for improvement.

    Args:
        df: Pandas DataFrame containing customer reviews. Must have a 'Review' and 'Final Sentiment' columns.

    Returns:
        A list of the top 5 areas for improvement.
    """
    if not all(col in df.columns for col in ['Review', 'Final Sentiment']):
        print("Error: 'Review' or 'Final Sentiment' columns not found in the DataFrame.")
        return []

    # Filter out positive reviews, focus on negative/neutral ones
    negative_reviews_df = df[df['Final Sentiment'] <= 0]

    if negative_reviews_df.empty:
        print("No negative or neutral reviews found to analyze for improvement.")
        return []

    all_negative_reviews = ' '.join(negative_reviews_df['Review'].astype(str).tolist()).lower()

    potential_issues = ["bug", "crash", "error", "glitch", "lag", "freeze", "slow", "performance", "unstable", "connectivity", "audio", "video", "screen sharing", "security", "integration", "customer support", "price", "interface", "user experience", "mobile app"]

    issue_counts = Counter({issue: all_negative_reviews.count(issue) for issue in potential_issues})

    # Get the top 5 most frequent issues
    top_5_issues = [issue for issue, count in issue_counts.most_common(5)]

    return top_5_issues


# Example usage
if 'df' in locals() and isinstance(df, pd.DataFrame):
    worst_features = analyze_worst_features(df)
    print("\nTop 5 areas for improvement:")
    for issue in worst_features:
        print(issue)
else:
    print("DataFrame 'df' not found or not properly initialized. Please run the previous code blocks first.")

import requests

# ✅ Airtable API Configuration
AIRTABLE_BASE_ID = "appScbEXV402S3pCE"  # Replace with your FinalProj1 base ID
AIRTABLE_TABLE_NAME = "performanceFactors"  # Your Sentiment Table name
AIRTABLE_API_KEY = "patWoTkjqabw7jy0J.a572ccaacd59b816f6f3f9397314ab3617713b3709a2d6856f1cc2dd47c49aed"  # Replace with your secure API key

# ✅ Airtable API Endpoint
AIRTABLE_API_URL = f"https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{AIRTABLE_TABLE_NAME}"

# ✅ Headers for API Authentication
HEADERS = {
    "Authorization": f"Bearer {AIRTABLE_API_KEY}",
    "Content-Type": "application/json"
}

# ✅ Function to Fetch Existing Records
def fetch_airtable_data():
    """Fetches all existing records from Airtable."""
    response = requests.get(AIRTABLE_API_URL, headers=HEADERS)
    if response.status_code == 200:
        return response.json().get("records", [])
    else:
        print(f"❌ Error fetching records: {response.status_code} - {response.text}")
        return []

# ✅ Function to Update Airtable Factors
def update_airtable_factors(record_id, factor_values):
    """Updates a record in Airtable with given factors."""
    url = f"{AIRTABLE_API_URL}/{record_id}"

    data = {
        "fields": {
            "Factor1": factor_values[0],
            "Factor2": factor_values[1],
            "Factor3": factor_values[2],
            "Factor4": factor_values[3],
            "Factor5": factor_values[4]
        }
    }

    response = requests.patch(url, headers=HEADERS, json=data)

    if response.status_code == 200:
        print(f"✅ Successfully updated record {record_id}")
    else:
        print(f"❌ Error updating record {record_id}: {response.status_code} - {response.text}")

# ✅ Run the Update Process
if 'top_features' in locals() and 'worst_features' in locals():
    # Fetch existing records to get IDs
    records = fetch_airtable_data()

    if len(records) >= 2:
        record1_id = records[0]['id']
        record2_id = records[1]['id']

        # ✅ Update the first record with positive factors
        positive_factors = top_features[:5] + [""] * (5 - len(top_features))  # Ensure 5 values
        update_airtable_factors(record1_id, positive_factors)

        # ✅ Update the second record with pain points
        pain_points = worst_features[:5] + [""] * (5 - len(worst_features))  # Ensure 5 values
        update_airtable_factors(record2_id, pain_points)

    else:
        print("❌ Not enough records found to update. Please add at least two rows.")
else:
    print("❌ 'top_features' or 'worst_features' variables not found.")

